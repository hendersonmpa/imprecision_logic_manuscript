:PROPERTIES:
- org-mode configuration
#+Latex_class: els-article
#+LANGUAGE:  en
#+OPTIONS:   title:nil author:nil date:nil  H:2 num:nil toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:
#+XSLT:
#+DRAWERS: LOGBOOK CLOCK HIDDEN PROPERTIES
#+SEQ_TODO: TODO(t) STARTED(s) DELEGATED(p) WAITING(w) | DONE(d) DEFERRED(f)
#+STARTUP: overview
#+STARTUP: noindent
#+bibliography: Collection.bib
#+cite_export: csl 
#+LaTeX_HEADER: \usepackage{lineno}
#+LaTeX_HEADER: \linenumbers
#+LaTeX_HEADER: \usepackage{setspace}
#+LaTeX_HEADER: \onehalfspacing
#+LaTeX_HEADER: \authblk
#+LaTeX_HEADER: \usepackage{pdfpages}
#+LaTeX_header: \usepackage{textpos}
#+LaTeX_header: \usepackage[final]{draftwatermark}
#+LaTeX_HEADER: \usepackage{gensymb}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{chemfig}
#+LaTeX_HEADER: \setchemfig{atom style={scale=0.45}}
#+LaTeX_HEADER: \usepackage[]{mhchem}
:END:

#+BEGIN_EXPORT LaTeX
\begin{frontmatter}
\title{Imprecision Logic}
\author[NSO, UoO]{Matthew P.A. Henderson\corref{cor1}}
\ead{mhenderson@cheo.on.ca}
\author[NSO]{Michael Kowalski}
\author[NSO, UO]{Pranesh Chakraborty}
\address[NSO]{Newborn Screening Ontario, Children's Hospital of Eastern Ontario,Canada}
\address[UoO]{Department of Medicine, University of Ottawa,Canada} 
\cortext[cor1]{Corresponding author}
\end{frontmatter}
#+END_EXPORT

* COMMENT Notes                                                          
** Focused Report
- The Focused Report category is intended for concise method
  evaluation contributions and succinct clinical manuscripts. All
  Focused Reports will undergo peer review.
- Submissions in this category should contain four sections:
  - Abstract (structured, no more than 250 words)
  - Introduction
  - Methods
  - Results
  - Discussion
  - An Impact Statement should appear after the abstract.
- They should be no more than 1,500 words in length with a maximum of
  20 references and a total of no more than two tables and
  figures. Figures and tables should not be multipart (i.e., Fig. 1A,
  1B, 1C, Part 1, Part 2). No more than 5 authors should be
  listed. Supplemental data are permitted for Focused Reports.

In some instances, editors may request that a submission of another article type to JALM be decreased to meet the requirements of a Focused Report.

* TODO Abstract (250 words)
- Introduction :: 
- Methods ::
- Results ::
- Conclusion :: 
* TODO Keywords
* STARTED Introduction

Newborn screening commonly uses algorithms based on biomarkers
measured in dried blood spot samples to identify neonates with an
increased probability of a target disorder. These screening
algorithms generally involve two or more phases of testing. All
samples are tested in the first phase and during this phase
sensitivity is emphasised over specificity, to identify samples with
higher probability of disease for additional investigation using an
approach that maintains high sensitivity with improved
specificity. Ideally an orthogonal analytical method or a different
biomarker(s) are employed in the second phase of screening, however in
a number of disorders the same assay is applied in duplicate during
the second phase of screening with a more specific confirmation
threshold applied to the mean of three biomarker measurements (Figure
[[fig:algorithm]]). This approach improves the precision of the final
screening result, reducing the chance that a sample will be deemed
screen negative due to analytical imprecision.

Screening threshold values used in newborn screening are set based on
the distribution of the biomarker: in the healthy population, the
affected population and specific sub-populations based on demographics
such as age, gestational age and birth weight. The goal of the
laboratory is to identify samples with abnormal biomarker results
relative to these screening thresholds. The imprecision of the
screening method at analyte concentrations near the screening
threshold is useful in determining an appropriate initial screen
threshold to prompt repeat testing and reduce the effect analytical
imprecision on screening determinations (Figure [[fig:algorithm]]). The
probability that a laboratory will incorrectly assign a screen
negative determination due to measurement error can be estimated from
the probability of a result near the screening in the screening
population and the imprecision of the method at the screening
threshold. This approach will be illustrated using the example of
newborn screening for galactosemia.

Newborn screening for galactosemia is based on measurement of
galactose-1-phosphate uridylyltransferase (GALT) activity in dried
blood spots. All samples are testing for GALT activity, GALT activity
is then tested in duplicate for all samples with activity below the
initial screening threshold. The mean of the three results is then
compared to the confirmation threshold. All results of the
confirmation phase are also subjected to medical scientific
review. Newborn screening for galactosemia will be used to demonstrate
the use of uncertainty of measurement for establishing thresholds in a
multi-stage testing algorithm, however this approach is applicable to
many testing scenarios in which biomarker results in a grey zone
must be identified for further investigation.

- Analytical drift due to factors such as calibrations and weather can
  result in periodic bias
- This should also be considered in determining impression logic



#+BEGIN_SRC dot :file ./figures/algorithm.pdf :cmdline -Kdot -Tpdf
    digraph {
        node [fontsize = 18];
        first[label="Biomarker Measurement",shape="rectangle",fontcolor=white,fillcolor=steelblue3, style="rounded,filled"];
        init[label="&#8804; Initial Cutoff",shape="diamond",fillcolor= grey85, style="rounded,filled"];
        second[label="Biomarker Measurement",shape="rectangle", fontcolor=white,fillcolor=steelblue3, style="rounded,filled"];
        conf[label="&#8804; Confirm Cutoff",shape="diamond",fillcolor= grey85, style="rounded,filled"];
        pos[label = "Screen\nPositive", shape="rectangle", fontcolor=white,fillcolor=darkviolet, style="rounded,filled"];
        neg[label = "Screen\nNegative", shape="box", fontcolor=white,fillcolor=forestgreen, style="rounded,filled"];
        first -> init;
        init -> second[label="Yes"];
        init -> neg[label="No"];
        second-> conf;
        conf -> pos[label="Yes"];
        conf -> neg[label="No"];
  }
#+END_SRC

#+CAPTION[]: Simplified Screening Algorithm for a Disorder with Low Biomarker Measurements 
#+NAME: fig:algorithm
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS:
[[file:./figures/algorithm.pdf]]

\clearpage

* TODO Material and Methods
** GALT Activity Data 
The laboratory information system was queried for all newborn
screening GALT activity results from the first phase of screening in
the period 2017-01-01 to 2018-12-31 (n = 285,875). This data was used
to determine the probability density function for GALT activity in the
population.

During the study period dried blood spot GALT activity was measured
on the SpotCheck Pro platform (Astoria Pacific, Oregon USA.). GALT
activity was reported in units per gram of hemoglobin (U/g Hb). 903
filter paper was used for dried blood spot sample collection (EBF,
South Carolina, USA).

** Assay Impression at Screening Threshold
The standard deviation of the GALT activity assay at the confirmation
threshold (1.5 U/g Hg) was determined based on six months of quality
control (QC) data for a QC material with mean GALT activity of 1.6 U/g
Hg.  *How many data points in six months of QC data*

** Simulation
A simulation was used to examine multiple initial screening thresholds
where each initial threshold (I) is the confirmation threshold (C)
plus K number of standard deviation for K from 0 to 6 (Equation
\ref{eq:initial}). For each value of K the predicted annual number of
samples in grey zone between the confirm and initial threshold was
estimated by the area in this region of the probability density
function of GALT activity in the population.

#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:initial}
I = C + K\sigma , \{n|0\ge K\le6\} 
\end{equation}
#+END_EXPORT

The number of samples potentially affected by measurement imprecision
at the screening threshold was estimated by the area under the
probability density function of measurement error after scaling for
the probability of a result at the confirmation threshold in the
population (Equation \ref{eq:scaled}). Imprecision at the screening
threshold was modelled using a standardized normal distribution with
mean (\mu) equal to the confirmation threshold, and the standard
deviation (\sigma) of quality control results at the screening
threshold (Equation \ref{eq:error}). For each value of K used to set
an initial threshold (Equation \ref{eq:initial}) the number of samples
predicted to be affected by measurement imprecision and not included
in the grey zone was determined.

#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:scaled}
f(x) = \frac{e^{-(x-\mu)^2/2\sigma^2}}{\sigma \sqrt[2]{2\pi}} \cdot Pr[GALT = Threshold] 
\end{equation}
#+END_EXPORT

#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:error}
X \sim N(\mu, \sigma^2)
\end{equation}
#+END_EXPORT

** TODO Software
The manuscript was prepared using the Org-mode environment for
literate programming and reproducible research
[cite:@Schulte2012]. The R language for statistical computing was used
for all data analysis with tidyverse packages for data manipulation,
*update*
[cite:@R2020;@tidyverse]. R scripts used for data
analysis are available here:
https://github.com/hendersonmpa/imprecision_logic_manuscript.git

* STARTED Results

Two considerations when determining where to set the initial threshold
in a two step screening algorithm (Figure [[fig:algorithm]]) are the
number of samples that would require repeat testing and the potential
for a false negative result during the first phase of testing. A
simulation was run to determine the number of samples that would fall
in the "grey zone" and require repeat testing and those in "false
negative zone" as a function of the GALT activity threshold used in
the initial phase of screening (Figure [[fig:imprecision]]). The "grey
zone" is the region between the initial and confirmation thresholds
and all samples with GALT activity in this range are repeated in
duplicate in the second phase of screening (Figure [[fig:algorithm]]). All
GALT results above the initial threshold are potentially false
negative however the probablity that the result is falsely negative do
to analytical imprecision is determined by the analytical imprecision
at the confirmation threshold and how far the result is from the
confirmation threshold. Figure [[fig:imprecision]] shows that a GALT result 1 \sigma
from the confirmation threshold falls within the false negative zone
(red area).

There is a trade-off between the number of samples that require repeat
testing and the number that could be false negative due to analytical
imprecision. The tolerance for a false negative first tier screening
results in newborn screening is very low, therefore, the most
appropriate expansion factor should be applied to avoid this
possibility. There is also a cost involved in repeat testing and the
use of sometime scarce sample. Table \ref{tab:imprecision} shows the
estimated number of samples in the repeat zone and false negative zone
annually.

#+begin_src R :session *R* :results values :exports none :tangle yes
  library("tidyverse")
  library("lubridate")
#  library("readxl")
  library("RODBC")
  library("xtable")
  options(warn=-1) ## options(warn=0) to turn back on
  ## Suppress summarise info
  today <- as.Date(now())
  source("credentials.r")

  ## rescale a vector from 0 to 1
  rescale <- function(x){
    (x-min(x))/(max(x)-min(x))
  }

  '%!in%' <- function(x,y)!('%in%'(x,y))

  ### accept data, initial and confirm thresholds
  ### return the area of the probability density polygon 
  densarea <- function(dens, lower, upper) {
    xx <- dens$x
    yy <- dens$y
    dx <- xx[2] - xx[1] ## determine the increment
    C <- sum(yy) * dx ## total area should be very close to 1
    p.unscaled <- sum(yy[xx >= lower & xx <= upper]) * dx 
    round(p.unscaled/C, digits = 5) ## scaled probablity
  }

  ## accept data, confirmation threshold, sd at the threshold, factor expansion factor
  ## return factor, lower, upper, grey area samples, uncertain area samples
  denssamples <- function(data, confirm, sd, factor , direction = "left", samples = 145000) {
    dens <- density(data)
    umsd  <- factor * sd
    sixsd  <- 6 * sd
    if (direction == "left") {
      ## calculate area between initial and confirm thresholds
      ## x value nearest the confirm threshold
      lower <- dens$x[min(which(dens$x >= confirm))]
      ## initial threshold based on the sd and factor
      initial <- confirm + umsd
      ## x value nearest the initial threshold
      upper <- dens$x[max(which(dens$x <= initial))]
      ## area of uncertainty distribution between the confirm and initial thresholds
      confirm_height  <- max(dens$y[which(dens$x <= confirm)])
      start  <- confirm - sixsd
      stop <- confirm + sixsd
      x2 <- seq(start,stop,0.01)
      y2 <- confirm_height*rescale(dnorm(x2,confirm,sd))
      ## TODO have a look here as the area does not seem correct
      uncertainy2 <- y2[length(x2[x2 <= initial]):length(x2)]
      uncertain_area <- 0.01 * sum(uncertainy2)
    } else {
      ## right sided threshold
      print("Right sided thresholds not implemented")
    }
    ## area of the probability density polygon between the initial and 6 sd above
    grey_area <- densarea(dens, lower, upper)
    grey_area_samples <- grey_area * samples
    uncertain_area_samples <- uncertain_area * samples
    list(factor, initial, grey_area_samples, uncertain_area_samples)
  }

#+end_src

#+RESULTS:

#+begin_src R :session *R* :results values :exports none :tangle yes :cache no
  galtquery <- "select s.spcextcode1 as accession,
	   a.ansTimeMeasured as measured_time,
	   s.spcExtcode2 as form,
	   sd.sd2GestationAge as ga,
	   sd.sd2Weight as bw,
	   sd.sd2AgeAtCollection as aoc,
	   a.ansvalueplain as result,
	   va.ResultCode as result_code
	   from (select s.specimenid, a.testid, max(answerix) as answerindex
	   from Answer a inner join specimen s on s.SpecimenID = a.SpecimenID
	   where a.TestId = 13 
	   and a.ansStatus = 110
	   and s.spcextcode1 like '[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'
	   and substring(s.spcextcode1,1,8) between '20170000' and '20190000'
	   and substring(s.spcextcode1,9,1) not in ('4', '7', '8')
	   group by s.specimenid, a.TestId) a1
	   inner join answer a on a1.SpecimenID = a.SpecimenID and a1.AnswerIndex = a.AnswerIX and a1.TestId = a.TestId
	   inner join specimen s on a1.specimenid = s.specimenid
	   inner join vw_Answers va on s.spcExtcode1 = va.AccessionNumber and a.TestId = va.TestID
	   inner join specimendetail2 sd on sd.SpecimenId = va.SpecimenID
	   order by s.spcextcode1"
  ## galtdata <- with_con(galtquery)
  ## write.csv(galtdata, file= paste0("./data/galt_data_", today, ".csv"))
  galtdata <- read.csv("./data/galt_data_2022-04-26.csv", stringsAsFactors = FALSE)
  galtdata$measured_time  <- ymd_hms(galtdata$measured_time)
  galtdata <- na.omit(galtdata)
  galtfilter <-  galtdata %>%
    filter( !result_code %in% c("GALT-C-01-100", "GALT-C-01-001", "GALT-C-01-012")) ## initial results only
    #filter(measured_time >= ymd_hms("2018-06-11 00:00:00") & !result_code %in% c("GALT-C-01-100", "GALT-C-01-001", "GALT-C-01-012")) ## initial result only
#+end_src

#+RESULTS:

#+begin_src R :session *R* :results output graphics file :file ./figures/galtthresholds.pdf :exports results :tangle yes
  dens <- density(galtfilter$result)
  sd <- 0.2 ##SD at postive confirm
  confirm  <- 1.5
  initial <- confirm + (6*sd)
  theight  <- max(dens$y[which(dens$x <= confirm)])
  bheight  <- max(dens$y[which(dens$x <= initial)])
  ## defining the region of FN uncertainty
  start  <- confirm - (6*sd)
  stop <- initial
  x2 <- seq(start,stop,0.01)
  y2 <- theight*rescale(dnorm(x2,confirm,sd))
  ## create indices for half of the UM distribution
  halfx2 <- seq(confirm,stop,0.01)
  halfy2 <- y2[length(halfx2):length(x2)]

  plot(x= 0:2*confirm, y = 0:2*bheight, type = "n",
       xlab = "U/g Hb",
       ylab = "density")

  polygon(dens,col = "steelblue", border = "steelblue")
  with(dens, polygon(x=c(initial, initial, x[x < initial]), y=c(0, y[x=initial], y[x < initial]), col="grey75", border = "grey75"))
  with(dens, polygon(x=c(x[x <= confirm], confirm, confirm), y=c(y[x <= confirm], y[x=confirm], 0), col = "black", border = "black"))

  ## area of uncertainty
  points(x2,y2,type="l",col="red") ## region of uncertainty of measurment
  zeros <- rep(0,length(halfx2)) # create a vector of zeros
  polygon(c(halfx2,rev(halfx2)),c(halfy2,zeros), border = NA, col="red")
  #area <- 0.01 * sum(halfy2)
  #samples <- round(area *145000, digits = 0)
  #text(x = 0.55, y = 0.004, label= paste("Annual results in red area:",samples), side = 3)

  abline(v = confirm, col = "red" , lty = 1, lwd = 2)
  abline(v = initial, col = "black", lty = 1, lwd = 2)
  abline(v = confirm + (1*sd), col = "black", lty = 2, lwd = 2) 

  legend("topleft",
	 legend = c("positive", "grey zone", "negative", 
		     "false negative zone","confirmation threshold",
		    expression(paste("1", sigma, " result")),
		    expression(paste("6", sigma, " threshold"))),
	 col = c("black", "grey75", "steelblue" , "red", "red", "black", "black"),
	 lty = c(NA, NA, NA, NA, "solid", "dashed", "solid"),
	 pch = c(15, 15, 15, 15, NA, NA, NA))
#+end_src

#+CAPTION[]: The left side of the GALT activity population distribution, illustrating the imprecsion at the confirmation threshold. 
#+NAME: fig:imprecision
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS:
[[file:./figures/galtthresholds.pdf]]


#+begin_src R :session *R* :results output latex :exports results :tangle yes
  ## initialize the dataframe
  galtarea <- data.frame(factor = double(), initial = double(),
			 grey = double(), imprecision = double(),
			 stringsAsFactors = FALSE)

	  ## populate the dataframe
  for (i in 0:6) {
    galtarea[i+1,] <- denssamples(galtfilter$result, 1.5, 0.2, i, direction = "left")
  }

  galtarea %>% rename("Expansion Factor" = factor,
		      "Initial Threshold" = initial,
		      "Grey Zone Samples" = grey,
		      "False Negative Zone Samples" =  imprecision) %>%
    xtable(caption = "Imprecision based initial threshold simulation results. In each simulation the conifirmation threshold is set to 1.5 U/g Hb and the initial thresholds is increased by a the corresponding expansion factor using (Equation \ref{eq:initial}) ",
	    label = "tab:imprecision", display = c("d", "d", "f", "f", "g")) %>%
	    print(include.rownames = FALSE)
    #+end_src

#+RESULTS:
#+begin_export latex
% latex table generated in R 4.0.3 by xtable 1.8-4 package
% Thu Apr 28 17:18:16 2022
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
Expansion Factor & Initial Threshold & Grey Area Samples & Imprecsion Area Samples \\ 
  \hline
  0 & 1.50 & 0.00 & 9.5 \\ 
    1 & 1.70 & 10.15 & 3.1 \\ 
    2 & 1.90 & 23.20 & 0.45 \\ 
    3 & 2.10 & 49.30 & 0.027 \\ 
    4 & 2.30 & 92.80 & 0.00066 \\ 
    5 & 2.50 & 142.10 & 6e-06 \\ 
    6 & 2.70 & 221.85 & 9.2e-23 \\ 
   \hline
\end{tabular}
\caption{Imprecision Based Initial Thresholds} 
\label{tab:imprecision}
\end{table}
#+end_export

\clearpage

* TODO Discussion

#+CAPTION[sigma]: Probability of a false negative screen due to imprecision
#+NAME: tab:sigma
| SD | probability of false negative | count
|----+-------------------------------+
|  1 |                     0.1586553 |
|  2 |                    0.02275013 |
|  3 |                   0.001349898 |
|  4 |                 3.167124ee-05 |
|  5 |                 2.866516ee-07 |
|  6 |                 9.865876ee-10 |

* TODO Conclusions

* DONE Acknowledgments
Funding: None.
* References
#+print_bibliography:

