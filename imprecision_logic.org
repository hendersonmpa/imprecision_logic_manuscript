:PROPERTIES:
- org-mode configuration
#+Latex_class: els-article
#+LANGUAGE:  en
#+OPTIONS:   title:nil author:nil date:nil  H:2 num:nil toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:
#+XSLT:
#+DRAWERS: LOGBOOK CLOCK HIDDEN PROPERTIES
#+SEQ_TODO: TODO(t) STARTED(s) DELEGATED(p) WAITING(w) | DONE(d) DEFERRED(f)
#+STARTUP: overview
#+STARTUP: noindent
#+bibliography: Collection.bib
#+cite_export: csl 
#+LaTeX_HEADER: \usepackage{lineno}
#+LaTeX_HEADER: \linenumbers
#+LaTeX_HEADER: \usepackage{setspace}
#+LaTeX_HEADER: \onehalfspacing
#+LaTeX_HEADER: \authblk
#+LaTeX_HEADER: \usepackage{pdfpages}
#+LaTeX_header: \usepackage{textpos}
#+LaTeX_header: \usepackage[final]{draftwatermark}
#+LaTeX_HEADER: \usepackage{gensymb}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{chemfig}
#+LaTeX_HEADER: \setchemfig{atom style={scale=0.45}}
#+LaTeX_HEADER: \usepackage[]{mhchem}
:END:

#+BEGIN_EXPORT LaTeX
\begin{frontmatter}
\title{Imprecision Logic}
\author[NSO, UoO]{Matthew P.A. Henderson\corref{cor1}}
\ead{mhenderson@cheo.on.ca}
\author[NSO]{Michael Kowalski}
\author[NSO, UO]{Pranesh Chakraborty}
\address[NSO]{Newborn Screening Ontario, Children's Hospital of Eastern Ontario,Canada}
\address[UoO]{Department of Medicine, University of Ottawa,Canada} 
\cortext[cor1]{Corresponding author}
\end{frontmatter}
#+END_EXPORT

* COMMENT Notes                                                          
** Focused Report
- The Focused Report category is intended for concise method
  evaluation contributions and succinct clinical manuscripts. All
  Focused Reports will undergo peer review.
- Submissions in this category should contain four sections:
  - Abstract (structured, no more than 250 words)
  - Introduction
  - Methods
  - Results
  - Discussion
  - An Impact Statement should appear after the abstract.
- They should be no more than 1,500 words in length with a maximum of
  20 references and a total of no more than two tables and
  figures. Figures and tables should not be multipart (i.e., Fig. 1A,
  1B, 1C, Part 1, Part 2). No more than 5 authors should be
  listed. Supplemental data are permitted for Focused Reports.

In some instances, editors may request that a submission of another article type to JALM be decreased to meet the requirements of a Focused Report.

* TODO Abstract (250 words)
- Introduction :: 
- Methods ::
- Results ::
- Conclusion :: 
* TODO Keywords
* STARTED Introduction

Newborn screening commonly uses algorithms based on biomarkers
measured in dried blood spot samples to identify neonates with an
increased probability of a target disorder. These screening algorithms
generally involve two or more phases of testing. All samples are
tested in the initial phase and during this phase sensitivity is
emphasized over specificity to identify samples with higher
probability of disease for additional investigation. The confirmatory
phase of testings uses an approach that maintains high sensitivity
with improved specificity. Ideally an orthogonal analytical method or
a different biomarker(s) are employed in the confirmatory phase of
testing, however in a number of disorders the same assay is applied in
duplicate with a more specific confirmation threshold applied to the
mean of the three resulting biomarker measurements (Figure
[[fig:algorithm]]). This approach improves the precision of the final
screening result, reducing the chance that a sample will be deemed
screen negative due to analytical imprecision.

Threshold values used in newborn screening are set based on the
distribution of the biomarker: in the healthy population, the affected
population and specific sub-populations based on demographics such as
age, gestational age and birth weight. The goal of the laboratory is
to identify samples with abnormal biomarker results relative to these
screening thresholds. When the same assay is used in both the initial
and confirmatory phases of screening the imprecision of the assay at
the confirmatory threshold is useful in determining an appropriate
initial threshold (Figure [[fig:algorithm]]). The probability that a
laboratory will incorrectly assign a screen negative determination due
to analytical imprecision can be estimated from the probability of a
result near the threshold the imprecision of the method at the
screening threshold. This approach will be illustrated using the
example of newborn screening for classic galactosemia
[cite:@Schweitzer1995].

In Ontario, Canada newborn screening for classic galactosemia is based
on measurement of galactose-1-phosphate uridylyltransferase (GALT)
activity in dried blood spots [cite:@Beutler1991]. All samples are
tested for GALT activity, this is repeated in duplicate for all
samples with activity below the initial threshold. The mean of the
three results is then assessed againset the confirmation threshold to
determine if the newborn is screen positive or negative for classic
galactosemia. The classic galactosemia screening process will be used
to demonstrate an approach for establishing initial thresholds in a
multi-stage testing algorithm based on biomarker distribution in a
population and analytical imprecision at the confirmation
threshold. While newborn screening is being used to demonstrate this
approach it is applicable to many testing scenarios in which biomarker
results in a grey zone must be identified for further investigation.


#+BEGIN_SRC dot :file ./figures/algorithm.pdf :cmdline -Kdot -Tpdf
    digraph {
        node [fontsize = 18];
        first[label="Biomarker Measurement",shape="rectangle",fontcolor=white,fillcolor=steelblue3, style="rounded,filled"];
        init[label="&#8804; Initial Cutoff",shape="diamond",fillcolor= grey85, style="rounded,filled"];
        second[label="Biomarker Measurement",shape="rectangle", fontcolor=white,fillcolor=steelblue3, style="rounded,filled"];
        conf[label="&#8804; Confirmatory Cutoff",shape="diamond",fillcolor= grey85, style="rounded,filled"];
        pos[label = "Screen\nPositive", shape="rectangle", fontcolor=white,fillcolor=darkviolet, style="rounded,filled"];
        neg[label = "Screen\nNegative", shape="box", fontcolor=white,fillcolor=forestgreen, style="rounded,filled"];
        first -> init;
        init -> second[label="Yes"];
        init -> neg[label="No"];
        second-> conf;
        conf -> pos[label="Yes"];
        conf -> neg[label="No"];
  }
#+END_SRC

#+CAPTION[]: Simplified Screening Algorithm for a Disorder with Low Biomarker Measurements 
#+NAME: fig:algorithm
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS:
[[file:./figures/algorithm.pdf]]

\clearpage

* STARTED Material and Methods
** GALT Activity Data 
The laboratory information system was queried for all newborn
screening GALT activity results from the first phase of screening in
the period 2017-01-01 to 2018-12-31 (n = 285,875). This data was used
to determine the probability density function for GALT activity in the
population.

During the study period dried blood spot GALT activity was measured
on the SpotCheck Pro platform (Astoria Pacific, Oregon USA.). GALT
activity was reported in units per gram of hemoglobin (U/g Hb). 903
filter paper was used for dried blood spot sample collection (EBF,
South Carolina, USA).

** Assay Impression at Screening Threshold
The standard deviation of the GALT activity assay at the confirmation
threshold (1.5 U/g Hg) was determined based on six months of quality
control (QC) data for a QC material with mean GALT activity of 1.6 U/g
Hg.  *How many data points in six months of QC data*

** Simulation
A simulation was used to examine multiple initial screening thresholds
where each initial threshold (I) is the confirmation threshold (C)
plus K number of standard deviation for K from 0 to 6 (Equation
\ref{eq:initial}). For each value of K the predicted annual number of
samples in grey zone between the confirm and initial threshold was
estimated by the area in this region of the probability density
function of GALT activity in the population.

#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:initial}
I = C + K\sigma , \{n|0\ge K\le6\} 
\end{equation}
#+END_EXPORT

The number of samples potentially affected by measurement imprecision
at the screening threshold was estimated by the area under the
probability density function of measurement error after scaling for
the probability of a result at the confirmation threshold in the
population (Equation \ref{eq:scaled}). Imprecision at the screening
threshold was modelled using a standardized normal distribution with
mean (\mu) equal to the confirmation threshold, and the standard
deviation (\sigma) of quality control results at the screening
threshold (Equation \ref{eq:error}). For each value of K used to set
an initial threshold (Equation \ref{eq:initial}) the number of samples
predicted to be affected by measurement imprecision and not included
in the grey zone was determined.

#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:scaled}
f(x) = \frac{e^{-(x-\mu)^2/2\sigma^2}}{\sigma \sqrt[2]{2\pi}} \cdot Pr[GALT = Threshold] 
\end{equation}
#+END_EXPORT

#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:error}
X \sim N(\mu, \sigma^2)
\end{equation}
#+END_EXPORT

** Software
The manuscript was prepared using the Org-mode environment for
literate programming and reproducible research
[cite:@Schulte2012]. The R language for statistical computing was used
for all data analysis with RODBC for relational database access,
tidyverse packages for data manipulation, lubridate for dates and
times and xtable for exporting tables to
\latex[cite:@R2020;@rodbc;@tidyverse;@lubridate;@xtable]. R scripts
used for data analysis are available here:
https://github.com/hendersonmpa/imprecision_logic_manuscript.git

* STARTED Results

Two considerations when determining the threshold value used in the
initial phase of a two step screening algorithm (Figure [[fig:algorithm]])
are the number of samples that would require repeat testing and the
potential for a false negative result during the first phase of
testing.  The "grey zone" is the region between the initial and
confirmation thresholds and all samples with GALT activity in this
range are repeated in duplicate in the second phase of screening
(Figure [[fig:algorithm]] and [[fig:imprecision]]). The "false negative zone"
is the region outside the "grey zone" but within the distribution of
analytical imprecision at the screening threshold (Figure
[[fig:imprecision]]). All GALT results above the initial threshold are
potentially false negative however the probablity that the result is
falsely negative do to analytical imprecision is determined by the
analytical imprecision at the confirmation threshold and how far the
result is from the confirmation threshold.

A simulation was run to determine the number of samples that would
fall in the "grey zone" and require repeat testing and those that in
the "false negative zone" as a function of the GALT activity threshold
used in the initial phase of screening (Table
[tab:imprecision]]). There is a trade-off between the number of
samples that require repeat testing and the number that could be false
negative due to analytical imprecision. In newborn screening the
tolerance for a false negative first tier screening result is very
low, therefore, the most appropriate expansion factor should be
applied to avoid this possibility. There is also a cost involved in
repeat testing and the possibility that there is not adequate sample
which would prompt recollection. Table \ref{tab:imprecision} shows the
estimated number of samples in the repeat zone and false negative zone
annually for a set of initial thresholds.

#+begin_src R :session *R* :results values :exports none :tangle yes
  library("tidyverse")
  library("lubridate")
#  library("readxl")
  library("RODBC")
  library("xtable")
  options(warn=-1) ## options(warn=0) to turn back on
  ## Suppress summarise info
  today <- as.Date(now())
  source("credentials.r")

  ## rescale a vector from 0 to 1
  rescale <- function(x){
    (x-min(x))/(max(x)-min(x))
  }

  '%!in%' <- function(x,y)!('%in%'(x,y))

  ### accept data, initial and confirm thresholds
  ### return the area of the probability density polygon 
  densarea <- function(dens, lower, upper) {
    xx <- dens$x
    yy <- dens$y
    dx <- xx[2] - xx[1] ## determine the increment
    C <- sum(yy) * dx ## total area should be very close to 1
    p.unscaled <- sum(yy[xx >= lower & xx <= upper]) * dx 
    round(p.unscaled/C, digits = 5) ## scaled probablity
  }

  ## accept data, confirmation threshold, sd at the threshold, factor expansion factor
  ## return factor, lower, upper, grey area samples, uncertain area samples
  denssamples <- function(data, confirm, sd, factor , direction = "left", samples = 145000) {
    dens <- density(data)
    umsd  <- factor * sd
    sixsd  <- 6 * sd
    if (direction == "left") {
      ## calculate area between initial and confirm thresholds
      ## x value nearest the confirm threshold
      lower <- dens$x[min(which(dens$x >= confirm))]
      ## initial threshold based on the sd and factor
      initial <- confirm + umsd
      ## x value nearest the initial threshold
      upper <- dens$x[max(which(dens$x <= initial))]
      ## area of uncertainty distribution between the confirm and initial thresholds
      confirm_height  <- max(dens$y[which(dens$x <= confirm)])
      start  <- confirm - sixsd
      stop <- confirm + sixsd
      x2 <- seq(start,stop,0.01)
      y2 <- confirm_height*rescale(dnorm(x2,confirm,sd))
      ## TODO have a look here as the area does not seem correct
      uncertainy2 <- y2[length(x2[x2 <= initial]):length(x2)]
      uncertain_area <- 0.01 * sum(uncertainy2)
    } else {
      ## right sided threshold
      print("Right sided thresholds not implemented")
    }
    ## area of the probability density polygon between the initial and 6 sd above
    grey_area <- densarea(dens, lower, upper)
    grey_area_samples <- grey_area * samples
    uncertain_area_samples <- uncertain_area * samples
    list(factor, initial, grey_area_samples, uncertain_area_samples)
  }

#+end_src

#+RESULTS:

#+begin_src R :session *R* :results values :exports none :tangle yes :cache no
  galtquery <- "select s.spcextcode1 as accession,
	   a.ansTimeMeasured as measured_time,
	   s.spcExtcode2 as form,
	   sd.sd2GestationAge as ga,
	   sd.sd2Weight as bw,
	   sd.sd2AgeAtCollection as aoc,
	   a.ansvalueplain as result,
	   va.ResultCode as result_code
	   from (select s.specimenid, a.testid, max(answerix) as answerindex
	   from Answer a inner join specimen s on s.SpecimenID = a.SpecimenID
	   where a.TestId = 13 
	   and a.ansStatus = 110
	   and s.spcextcode1 like '[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'
	   and substring(s.spcextcode1,1,8) between '20170000' and '20190000'
	   and substring(s.spcextcode1,9,1) not in ('4', '7', '8')
	   group by s.specimenid, a.TestId) a1
	   inner join answer a on a1.SpecimenID = a.SpecimenID and a1.AnswerIndex = a.AnswerIX and a1.TestId = a.TestId
	   inner join specimen s on a1.specimenid = s.specimenid
	   inner join vw_Answers va on s.spcExtcode1 = va.AccessionNumber and a.TestId = va.TestID
	   inner join specimendetail2 sd on sd.SpecimenId = va.SpecimenID
	   order by s.spcextcode1"
  ## galtdata <- with_con(galtquery)
  ## write.csv(galtdata, file= paste0("./data/galt_data_", today, ".csv"))
  galtdata <- read.csv("./data/galt_data_2022-04-26.csv", stringsAsFactors = FALSE)
  galtdata$measured_time  <- ymd_hms(galtdata$measured_time)
  galtdata <- na.omit(galtdata)
  galtfilter <-  galtdata %>%
    filter( !result_code %in% c("GALT-C-01-100", "GALT-C-01-001", "GALT-C-01-012")) ## initial results only
    #filter(measured_time >= ymd_hms("2018-06-11 00:00:00") & !result_code %in% c("GALT-C-01-100", "GALT-C-01-001", "GALT-C-01-012")) ## initial result only
#+end_src

#+RESULTS:

#+begin_src R :session *R* :results output graphics file :file ./figures/galtthresholds.pdf :exports results :tangle yes
  dens <- density(galtfilter$result)
  sd <- 0.2 ##SD at postive confirm
  confirm  <- 2.0
  initial <- confirm + (1.1*sd)
  theight  <- max(dens$y[which(dens$x <= confirm)])
  bheight  <- max(dens$y[which(dens$x <= initial)])
  ## defining the region of FN uncertainty
  start  <- confirm - (6*sd)
  stop <- confirm + (6*sd)
  x2 <- seq(start,stop,0.01)
  y2 <- theight*rescale(dnorm(x2,confirm,sd))
  ## create indices for half of the UM distribution
  halfx2 <- seq(confirm,stop,0.01)
  halfy2 <- y2[length(halfx2):length(x2)]

  fnx2 <- seq(initial,stop,0.01)
  fny2 <- y2[(length(x2) - length(fnx2)):(length(x2) -1)]

  plot(x= 0:2*confirm, y = 0:2*bheight, type = "n",
       xlab = "U/g Hb",
       ylab = "density")

  polygon(dens,col = "steelblue", border = "steelblue")
  with(dens, polygon(x=c(initial, initial, x[x < initial]), y=c(0, y[x=initial], y[x < initial]), col="grey75", border = "grey75"))
  with(dens, polygon(x=c(confirm, confirm, x[x < confirm]), y=c(0, y[x=confirm], y[x < confirm]), col="black", border = "black"))

  ## area of uncertainty
  points(x2,y2,type="l",col="red", lwd = 4) ## region of uncertainty of measurment
  zeros <- rep(0,length(x2)) # create a vector of zeros
  #polygon(c(x2,rev(x2)),c(y2,zeros), border = NA, col="red")

  #polygon(c(halfx2,rev(halfx2)),c(halfy2,zeros), border = NA, col="red")
  fnzeros <- rep(0,length(fnx2)) # create a vector of zeros
  polygon(c(fnx2,rev(fnx2)),c(fny2,fnzeros), border = NA, col="red")
  #area <- 0.01 * sum(halfy2)
  #samples <- round(area *145000, digits = 0)
  #text(x = 0.55, y = 0.004, label= paste("Annual results in red area:",samples), side = 3)

  abline(v = confirm, col = "black" , lty = 1, lwd = 3)
  abline(v = initial, col = "black", lty = 2, lwd = 3)
  #abline(v = confirm + (1*sd), col = "black", lty = 2, lwd = 2) 

  legend("topleft",
	 legend = c("positive", "grey zone", "negative", 
		     "false negative zone","confirmation threshold",
		    expression(paste("1", sigma, " threshold"))),
	 col = c("black", "grey75", "steelblue" , "red", "black", "black"),
	 lty = c(NA, NA, NA, NA, "solid", "dashed"),
	 pch = c(15, 15, 15, 15, NA, NA))
#+end_src

#+CAPTION[]: The left side of the GALT activity population distribution, illustrating the imprecsion at the confirmation threshold. 
#+NAME: fig:imprecision
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS:
[[file:./figures/galtthresholds.pdf]]


#+begin_src R :session *R* :results output latex :exports results :tangle yes
  ## initialize the dataframe
  galtarea <- data.frame(factor = double(), initial = double(),
			 grey = double(), imprecision = double(),
			 stringsAsFactors = FALSE)

	  ## populate the dataframe
  for (i in 0:6) {
    galtarea[i+1,] <- denssamples(galtfilter$result, 1.5, 0.2, i, direction = "left")
  }

  galtarea %>% rename("Expansion Factor" = factor,
		      "Initial Threshold" = initial,
		      "Grey Zone Samples" = grey,
		      "False Negative Zone Samples" =  imprecision) %>%
    xtable(caption = "Imprecision based initial threshold simulation results. In each simulation the conifirmation threshold is set to 1.5 U/g Hb and the initial thresholds is increased by a the corresponding expansion factor using (Equation \ref{eq:initial}) ",
	    label = "tab:imprecision", display = c("d", "d", "f", "f", "g")) %>%
	    print(include.rownames = FALSE)
    #+end_src

#+RESULTS:
#+begin_export latex
% latex table generated in R 4.0.3 by xtable 1.8-4 package
% Thu Apr 28 17:18:16 2022
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
Expansion Factor & Initial Threshold & Grey Area Samples & Imprecsion Area Samples \\ 
  \hline
  0 & 1.50 & 0.00 & 9.5 \\ 
    1 & 1.70 & 10.15 & 3.1 \\ 
    2 & 1.90 & 23.20 & 0.45 \\ 
    3 & 2.10 & 49.30 & 0.027 \\ 
    4 & 2.30 & 92.80 & 0.00066 \\ 
    5 & 2.50 & 142.10 & 6e-06 \\ 
    6 & 2.70 & 221.85 & 9.2e-23 \\ 
   \hline
\end{tabular}
\caption{Imprecision Based Initial Thresholds} 
\label{tab:imprecision}
\end{table}
#+end_export

\clearpage

* STARTED Discussion

We have used a testing algorithm used in newborn screening for
galactosemia to demonstrate how data on analytical imprecision and
biomarker distribution in a population and can be used to evaluate
screening thresholds. The ideas discussed here are second nature to
the clinical laboratory professional; there is analytical imprecision
in all laboratory results and results at the extremes of the
population distribution are rare. The utility of this approach is in
combining this information to get an estimate the impact in terms of
false negative results and the number of samples sent for confirmatory
testing based on the analytical impression of results near a
clinically relevant threshold value, this could be a screening
threshold or a diagnostic threshold. This information could be used to
decided on appropriate initial phase thresholds and plan for the
number of samples expected to require confirmatory testing.

While a use case in newborn screening was used to demonstrate this
approach it is applicable to any area of laboratory medicine where a
sensitive test is used to identify samples that require additional
investigation with a more complex and informative method. Examples
from other areas of laboratory medicine include but are by no means
limited to confirmation of hepatitis B serology results,
spectrophotometric measurement of total urine porphyrins to identify
samples that require chromatographic fractionation of urine
porphyrins, confirmation of low point of care glucose results by the
central laboratory [cite:@Chen2006;@Deacon2001e;@Lum1996].

The approach outlined here has focused exclusively on the impact of
method precision on a two phase testing process. Analytical bias and
pre-analytical factors are two categories of error that have not been
incorporated into the estimate of error at a threshold value however
this approach could be extended to incorporate total uncertainty of
measurement [cite:@White2004].

* DONE Acknowledgments
Funding: None.
* References
#+print_bibliography:

