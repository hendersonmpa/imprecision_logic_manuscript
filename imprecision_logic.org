:PROPERTIES:
- org-mode configuration
#+Latex_class: els-article
#+LANGUAGE:  en
#+OPTIONS:   title:nil author:nil date:nil  H:2 num:nil toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:
#+XSLT:
#+DRAWERS: LOGBOOK CLOCK HIDDEN PROPERTIES
#+SEQ_TODO: TODO(t) STARTED(s) DELEGATED(p) WAITING(w) | DONE(d) DEFERRED(f)
#+STARTUP: overview
#+STARTUP: noindent
#+bibliography: Collection.bib
#+cite_export: csl pnas.csl
#+LaTeX_HEADER: \usepackage{lineno}
#+LaTeX_HEADER: \linenumbers
#+LaTeX_HEADER: \usepackage{setspace}
#+LaTeX_HEADER: \onehalfspacing
#+LaTeX_HEADER: \authblk
#+LaTeX_HEADER: \usepackage{pdfpages}
#+LaTeX_header: \usepackage{textpos}
#+LaTeX_header: \usepackage[final]{draftwatermark}
#+LaTeX_HEADER: \usepackage{gensymb}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{chemfig}
#+LaTeX_HEADER: \setchemfig{atom style={scale=0.45}}
#+LaTeX_HEADER: \usepackage[]{mhchem}
:END:

#+BEGIN_EXPORT LaTeX
\newcommand{\beginsupplement}{%
        \setcounter{table}{0}
        \renewcommand{\thetable}{S\arabic{table}}%
        \setcounter{figure}{0}
        \renewcommand{\thefigure}{S\arabic{figure}}%
     }
\begin{frontmatter}
\title{An Approach for Evaluating Potential Screening Thresholds used in a Multi-Stage Testing Algorithm Using Biomarker Population Distribution and Analytical Imprecision}
\author[NSO, UoO]{Matthew P.A. Henderson\corref{cor1}}
\ead{mhenderson@cheo.on.ca}
\author[NSO, UO]{Pranesh Chakraborty}
\address[NSO]{Newborn Screening Ontario, Children's Hospital of Eastern Ontario, Ottawa, Canada}
\address[UoO]{Department of Medicine, University of Ottawa, Ottawa, Canada} 
\cortext[cor1]{Corresponding author}
\end{frontmatter}
#+END_EXPORT

* Abstract
- Background :: A common approach in laboratory medicine is to use a
  simple but sensitive test to screen samples to identify those that
  require additional investigation with a more complex and informative
  method. Selection of screening thresholds can be guided by biomarker
  distribution in the tested population and analytical imprecision of
  the method.
- Methods :: A simulation using joint probabilities derived from the
  population distribution for galactose-1-phosphate
  uridylyltransferase (GALT) activity and analytical imprecision for
  the GALT assay was used to estimate the number of samples that would
  require repeat analysis and the number of samples with possibly
  false negative screening determinations due to analytical
  imprecision.
- Results :: In the case of GALT activity screening a conservative
  initial threshold six standard deviations from the confirmation
  threshold can essentially eliminate the chance of a false negative
  screening determination due to analytical imprecision, the trade off
  is a greater number of samples requiring follow-up testing (n = 222
  annually).
- Conclusions :: Selection of thresholds in a screening algorithm is
  informed by estimates of the number of samples that would require
  repeat testing and the number that could be false negative due to
  analytical imprecision.

* Impact Statement
  It is common in laboratory medicine to use a simple but sensitive
  test to screen samples for additional investigation with a more
  complex and informative method. The choice of screening threshold
  affects both the number of samples that will require subsequent
  testing and the number of false negative results. A simulation based
  on joint probabilities derived from the biomarkers distribution in
  the tested population and analytical imprecision of the method can
  be used to estimate the impact of a chosen screening threshold.

* Introduction
Newborn screening commonly uses algorithms based on biomarkers
measured in dried blood spot samples to identify neonates with an
increased probability of a target disorder. These screening algorithms
generally involve two or more phases of testing. All samples are
tested in the initial phase and during this phase sensitivity is
emphasized over specificity to identify samples with higher
probability of disease for additional investigation. The confirmatory
phase of testing uses an approach that maintains high sensitivity
with improved specificity. Ideally an orthogonal analytical method or
a different biomarker(s) is employed in the confirmatory phase of
testing, however in a number of disorders the same assay is applied in
duplicate with a more specific confirmation threshold applied to the
mean of the three resulting biomarker measurements (Supplementary Figure
[[sup:algorithm]]). This approach improves the precision of the final
screening result, reducing the chance that a sample will be deemed
screen negative due to analytical imprecision.

Confirmatory threshold values used in newborn screening are set based
on the distribution of the biomarker: in the healthy population, the
affected population and specific sub-populations based on demographics
such as age, gestational age and birth weight. The goal of the
laboratory is to identify samples with abnormal biomarker results
relative to these confirmatory thresholds. When the same assay is used
in both the initial and confirmatory phases of screening the
imprecision of the assay at the confirmatory threshold is useful in
determining an appropriate initial threshold. The probability that a
laboratory will incorrectly assign a screen negative determination due
to analytical imprecision can be estimated from the joint probability
of a result near the initial threshold and the imprecision of the
method at the confirmation threshold. This approach will be
illustrated for newborn screening for classic galactosemia
[cite:@Schweitzer1995;@Beutler1991]. While newborn screening is being
used to demonstrate this approach it is applicable to many testing
scenarios in which biomarker results in a grey zone must be identified
for further investigation.

* Materials and Methods
** GALT Activity Data 
The laboratory information system was queried for all newborn
screening GALT activity results from the first phase of screening in
the period 2017-01-01 to 2018-12-31 (n = 285,875). This data was used
to determine the probability density function for GALT activity in the
population.

During the study period dried blood spot GALT activity was measured
on the SpotCheck Pro platform (Astoria Pacific, Oregon USA.). GALT
activity was reported in units per gram of hemoglobin (U/g Hb). 903
filter paper was used for dried blood spot sample collection (EBF,
South Carolina, USA).

** Assay Imprecision 
The standard deviation of the GALT activity assay at the confirmation
threshold (1.5 U/g Hg) was estimated based on six months of quality
control (QC) data for a QC material with mean GALT activity of 1.6 U/g
Hg (n = 1812)

** Simulation
The population distribution of GALT activity results and the
imprecision at the confirmatory threshold were used to estimate the
number of potentially false negative samples due to measurement
imprecision near the confirmation threshold. Analytical imprecision at
the confirmation threshold was modelled using a standardized normal
distribution with mean (\mu) equal to the confirmation threshold, and
the standard deviation (\sigma) of quality control results near the
confirmation threshold. The probability that a measured GALT activity
result /x/ could arise when the true value is equal to the confirmation
threshold can be determined from the height of the probability
distribution for analytical imprecision at /x/ (Ye_x). Similarly, the
probability of GALT activity /x/ in the population can be determined
from the height of this probability distribution at /x/ (Yp_x). The
joint probability (Ye_x \cdot Yp_x) of the above conditions provides
an estimate of probability of a false negative result due to analytical
imprecision for GALT result /x/. The joint probabilities were then
summed over a given range to determine the probability of a false
negative result due to analytical imprecision for a range of GALT
results (Equation \ref{eq:joint}).


#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:joint}
p = \sum_{x=a}^b Ye_x \cdot Yp_x \cdot dx
\end{equation}
#+END_EXPORT

A simulation was used to examine multiple initial screening thresholds
where each initial threshold (I) is the confirmation threshold (C)
plus /k/ number of standard deviations, for /k/ from 0 to 6 (Equation
\ref{eq:initial}). For each value of /k/ the predicted annual number
of samples in grey zone between the confirm and initial threshold was
estimated by the area in this region of the probability density
function of GALT activity in the population using the numerical
integration (Equation \ref{eq:grey}). The number of samples with GALT
results above the initial threshold and potentially affected by
analytical imprecision was estimated using the joint probabilities
(Ye_x \cdot Yp_x) summed from the initial threshold to 7 standard
deviations from the confirmation threshold (Equation
\ref{eq:imprecision}).

#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:initial}
I = C + k\sigma 
\end{equation}
#+END_EXPORT

#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:grey}
\text{grey zone samples}  =  n \cdot \sum_{x=confirm}^{initial} Yp_x \cdot dx
\end{equation}
#+END_EXPORT

#+BEGIN_EXPORT LaTeX
\begin{equation}\label{eq:imprecision}
\text{imprecision zone samples}  =  n \cdot \sum_{x=initial}^{7\sigma} Ye_x \cdot Yp_x \cdot dx
\end{equation}
#+END_EXPORT

** Software
The manuscript was prepared using the Org-mode environment for
literate programming and reproducible research
[cite:@Schulte2012]. The R language for statistical computing was used
for all data analysis with RODBC for relational database access,
tidyverse packages for data manipulation, lubridate for dates and
times and xtable for exporting tables to
\LaTeX  [cite:@R2020;@rodbc;@tidyverse;@lubridate;@xtable]. R scripts
used for data analysis are available here:
https://github.com/hendersonmpa/imprecision_logic_manuscript.git

* Results

Two considerations when determining the threshold value used in the
initial phase of a two step screening algorithm (Supplementary Figure
[[sup:algorithm]]) are the number of samples that will require repeat
testing and the potential for a false negative result during the first
phase of testing.  The "grey zone" is the region between the initial
and confirmation thresholds and all samples with GALT activity in this
range are repeated in duplicate in the second phase of screening
(Figure [[fig:imprecision]]). The "imprecision zone" is the region outside
the "grey zone" but within the distribution of analytical imprecision
at the confirmation threshold (7\sigma above the confirmation
threshold) (Figure [[fig:imprecision]], gold area). 

A simulation was run to determine the number of samples that would
fall in the "grey zone" and those potentially affected by analytical
imprecision in "imprecision zone" as a function of the GALT activity
threshold used in the initial phase of screening (Table
\ref{tab:imprecision}). There is a trade-off between the number of
samples that require repeat testing and the number that could be false
negative due to analytical imprecision. Table \ref{tab:imprecision}
shows the estimated number of samples in the "grey-zone" and
"imprecision zone" annually for a set of initial thresholds. For
example, an initial threshold 1 standard deviation from the
confirmation threshold (GALT activity = 1.70 U/g Hb) would result in
\sim 10 samples in the grey zone (Figure [[fig:imprecision]] grey area)
annually with \sim 15 samples in the "imprecision zone" (Figure
[[fig:imprecision]], joint probablity based on red and gold areas). In
contrast an initial threshold 6 standard deviations from the
confirmation threshold (GALT activity = 2.70 U/g Hb) from would result
in \sim 222 samples in the grey zone annually with essentially zero
samples in the "imprecision zone". The risk tolerance for a false
negative first tier screening result for classic galactosemia is very
low in our program, we therefore adopted an initial threshold 6
standard deviations from the confirmation threshold.

* Discussion

We have used a newborn screening algorithm for classic galactosemia to
demonstrate how analytical imprecision and biomarker distribution in a
population and can be used to inform decisions on screening
thresholds. The utility of this approach is in combining analytical
imprecision and population information as a joint probability in order
to estimate the number of possible false negative results and the
number of samples sent for confirmatory testing for a given threshold
value. These estimates could be used to decided on the most
appropriate initial phase thresholds and plan for the number of
samples expected to require more expensive and labour intensive
confirmatory testing.

While a newborn screening scenario was used to demonstrate this
approach it is applicable to any area of laboratory medicine where a
sensitive test is used to identify samples that require additional
investigation with a more complex and informative method. Examples
from other areas of laboratory medicine include but are by no means
limited to confirmation of hepatitis B serology results with an
antibody neutralization assay, spectrophotometric measurement of total
urine porphyrins to identify samples that require chromatographic
fractionation, confirmation of low point of care glucose results by
the central laboratory [cite:@Chen2006;@Deacon2001e;@Lum1996].

The approach outlined here has focused exclusively on the impact of
analytical imprecision on a two phase testing process. Analytical bias
and pre-analytical factors are two categories of error that have not
been incorporated into the estimate of error at a threshold value
however this approach could be extended to incorporate total
uncertainty of measurement [cite:@White2004].

* Acknowledgments
Funding: None.
* Author Declarations
- Author Contributions :: All authors confirmed they have contributed
  to the intellectual content of this paper and have met the following
  4 requirements:
  1. Significant contributions to the conception and design, acquisition of data, or analysis and interpretation of data
  2. Drafting or revising the article for intellectual content
  3. Final approval of the published article
  4. Agreement to be accountable for all aspects of the article thus
     ensuring that questions related to the accuracy or integrity of
     any part of the article are appropriately investigated and
     resolved.

- Authorsâ€™ Disclosures or Potential Conflicts of Interest :: No authors declared any potential conflicts of interest.
* References
#+print_bibliography:
\clearpage 

* Tables 

#+begin_src R :session *R* :results values :exports none :tangle yes
  library("tidyverse")
  library("lubridate")
  ## library("readxl")
  library("RODBC")
  library("xtable")
  library("pander")
  library("scales")
  options(warn=-1) ## options(warn=0) to turn back on
  ## Suppress summarise info
  today <- as.Date(now())
  source("credentials.r")

  ## rescale a vector from 0 to 1
  rescale <- function(x){
    (x-min(x))/(max(x)-min(x))
  }

  '%!in%' <- function(x,y)!('%in%'(x,y))

  ### accept data, initial and confirm thresholds
  ### return the area of the probability density polygon 
  densprob <- function(dens, lower, upper) {
    x <- dens$x
    y <- dens$y
    dx <- x[2] - x[1] ## determine the increment
    C <- sum(y) * dx ## total area should be very close to 1
    p.unscaled <- sum(y[x >= lower & x <= upper]) * dx 
    round(p.unscaled/C, digits = 5) ## scaled probablity
  }


  ## Calculate the joint probability of the sample distribution and the imprecsion distribution for each y from the initial threshold to 6 SD
  jointprob  <- function(dens, confirm, sd, lower, upper) {
					  #dens <- density(pop_data)
    x <- dens$x
    y <- dens$y
    dx <- x[2] - x[1] ## determine the increment
    pop_dens_region <- y[x >= lower & x <= upper] ##trim the pop dens to the region of interest

    ## create the imprecision region
    start <- confirm - (6*sd)
    stop <- confirm + (6*sd)
    x2 <- seq(start,stop,dx)
    y2 <- dnorm(x2,confirm,sd)
    imp_dens_region <- y2[x2 >= lower & x2 <= upper] ##trim the imprecision dens to the region of interest
					  #Create a dataframe with the Ys from both densities side by side
    sum(pop_dens_region * imp_dens_region) * dx
  }

  ## Testing
  ## jointprob(galtfilter$result, 1.5, 2.7, 3.2)
  ## jointprob(galtfilter$result, 1.5, 1.5, 3.2)

  ## accept a density object, confirmation threshold, sd at the threshold, factor expansion factor
  ## return factor, lower, upper, grey area samples, uncertain area samples
  denssamples <- function(dens, confirm, sd, factor , direction = "left", samples = 145000) {
    umsd  <- factor * sd
    sevensd  <- 7 * sd
    if (direction == "left") {
      ## initial threshold based on the sd and factor
      initial <- confirm + umsd
      end <- confirm + sevensd
      ## grey area between the confirm and initial thresholds
      grey_area <- densprob(dens, confirm, initial)
      ## Calculate the joint probability of the sample distribution and the imprecsion distribution for each value from the initial threshold to 6 SD
      imprecision_area <- jointprob(dens, confirm, sd, initial, end)

    } else {
      ## right sided threshold
      print("Right sided thresholds not implemented")
    }
    ## area of the probability density polygon between the initial and 6 sd above
    grey_samples <- grey_area * samples
    imprecision_samples <- imprecision_area * samples
    list(factor, initial, grey_samples, imprecision_samples)
  }
  
    #+end_src

    #+RESULTS:

#+begin_src R :session *R* :results values :exports none :tangle yes :cache no
  galtquery <- "select s.spcextcode1 as accession,
	   a.ansTimeMeasured as measured_time,
	   s.spcExtcode2 as form,
	   sd.sd2GestationAge as ga,
	   sd.sd2Weight as bw,
	   sd.sd2AgeAtCollection as aoc,
	   a.ansvalueplain as result,
	   va.ResultCode as result_code
	   from (select s.specimenid, a.testid, max(answerix) as answerindex
	   from Answer a inner join specimen s on s.SpecimenID = a.SpecimenID
	   where a.TestId = 13 
	   and a.ansStatus = 110
	   and s.spcextcode1 like '[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'
	   and substring(s.spcextcode1,1,8) between '20170000' and '20190000'
	   and substring(s.spcextcode1,9,1) not in ('4', '7', '8')
	   group by s.specimenid, a.TestId) a1
	   inner join answer a on a1.SpecimenID = a.SpecimenID and a1.AnswerIndex = a.AnswerIX and a1.TestId = a.TestId
	   inner join specimen s on a1.specimenid = s.specimenid
	   inner join vw_Answers va on s.spcExtcode1 = va.AccessionNumber and a.TestId = va.TestID
	   inner join specimendetail2 sd on sd.SpecimenId = va.SpecimenID
	   order by s.spcextcode1"
  ## galtdata <- with_con(galtquery)
  ## write.csv(galtdata, file= paste0("./data/galt_data_", today, ".csv"))
  galtdata <- read.csv("./data/galt_data_2022-04-26.csv", stringsAsFactors = FALSE)
  galtdata$measured_time  <- ymd_hms(galtdata$measured_time)
  galtdata <- na.omit(galtdata)
  galtfilter <-  galtdata %>%
    filter( !result_code %in% c("GALT-C-01-100", "GALT-C-01-001", "GALT-C-01-012")) ## initial results only
  #+end_src

#+RESULTS:

#+begin_src R :session *R* :results values :exports none :tangle yes
  annual_volume <- 145000
  start <- 0
  end <- 6
  mean <- 1.5
  sd <- 0.2

  ## initialize the dataframe
  galtarea <- data.frame(factor = double(), initial = double(),
			 grey = double(), imprecision = double(),
			 stringsAsFactors = FALSE)

  ## stochastic simulation
  c <- 0
  for (s in 1:1000) {
    data_sample <- sample(galtfilter$result, size = annual_volume, replace = TRUE)
    d <- density(data_sample)
    for (i in seq(from = start, to = end, by = 1)) {
      c <- c + 1
      galtarea[c,] <- denssamples(d, confirm = 1.5, sd = 0.2, factor = i)
      # denssamples(d, confirm = 1.5, sd = 0.2, factor = i)
    }
  }

#+end_src

#+RESULTS:

#+begin_src R :session *R* :results output latex :exports results :tangle yes
  galtarea %>%
    group_by(factor, initial) %>%
    summarise(grey_p025 = quantile(grey,probs = c(0.025), type = 8, na.rm = TRUE),
	      grey_median = median(grey, na.rm = TRUE),
	      grey_p975 = quantile(grey,probs = c(0.975), type = 8, na.rm = TRUE),
	      imp_p025 = quantile(imprecision,probs = c(0.025), type = 8, na.rm = TRUE),
	      imp_median = median(imprecision, na.rm = TRUE),
	      imp_p975 = quantile(imprecision,probs = c(0.975), type = 8, na.rm = TRUE)) %>%
    xtable(caption = "Initial Threshold Simulation Results. In each simulation the confirmation threshold is set to 1.5 U/g Hb and the initial thresholds is increased by the corresponding number of standard deviations",
	   label = "tab:imprecision", display = c("d", "d", "f","f", "f", "f", "g", "g","g")) %>%
    print(include.rownames = FALSE)

#+end_src


#+RESULTS:
#+begin_export latex
Error: unexpected symbol in:
"for (s in 1:1000) {
  data_sample <- sample(galtfilter$result, size = annual_volume, replace = TRUE)o"
Error: unexpected '}' in "}"
[1m[33mError[39m in [1m[1m`summarise()`:[22m
[1m[22m[33m![39m Problem while computing `imp_p975 = quantile(imprecsion, probs = c(0.975), type = 8, na.rm =
  TRUE)`.
[36mâ„¹[39m The error occurred in group 1: factor = 0.
[1mCaused by error in [1m[1m`quantile()`:[22m
[33m![39m object 'imprecsion' not found
[90mRun `rlang::last_error()` to see where the error occurred.[39m
#+end_export

\clearpage

* Figures 

#+begin_src R :session *R* :results output graphics file :file ./figures/galtthresholds.pdf :exports results :tangle yes
  dens <- density(galtfilter$result)
  sd <- 0.2 ##SD at postive confirm
  confirm  <- 1.5
  initial <- confirm + (1.1*sd)
  theight  <- max(dens$y[which(dens$x <= confirm)])
  bheight  <- max(dens$y[which(dens$x <= initial)])
  ## defining the region of FN uncertainty
  start  <- confirm - (6*sd)
  stop <- confirm + (6*sd)
  x2 <- seq(start,stop,0.01)
  y2 <- theight*rescale(dnorm(x2,confirm,sd))
  ## create indices for half of the UM distribution
  halfx2 <- seq(confirm,stop,0.01)
  halfy2 <- y2[length(halfx2):length(x2)]
  fnx2 <- seq(initial,stop,0.01)
  fny2 <- y2[(length(x2) - length(fnx2)):(length(x2) -1)]

  plot(x= 0:2*confirm, y = 0:2*bheight, type = "n",
       xlab = "GALT Activity U/g Hb",
       ylab = "Probability Density")
  ### polygons
  polygon(dens,col = "steelblue", border = "steelblue")
  ## imprecision zome
  with(dens, polygon(x=c(stop, stop, x[x < stop]), y=c(0, y[x=stop], y[x < stop]), col="goldenrod", border = "goldenrod"))
  ## grey zone
  with(dens, polygon(x=c(initial, initial, x[x < initial]), y=c(0, y[x=initial], y[x < initial]), col="grey75", border = "grey75"))
  ## positive
  with(dens, polygon(x=c(confirm, confirm, x[x < confirm]), y=c(0, y[x=confirm], y[x < confirm]), col="black", border = "black"))

  ## measurement error distribution
  points(x2,y2,type="l",col="red", lwd = 4) ## region of uncertainty of measurment
  zeros <- rep(0,length(x2)) # create a vector of zeros
  fnzeros <- rep(0,length(fnx2)) # create a vector of zeros
  polygon(c(fnx2,rev(fnx2)),c(fny2,fnzeros), border = NA, col="red")

  abline(v = confirm, col = "black" , lty = 1, lwd = 2)
  abline(v = initial, col = "black", lty = 2, lwd = 2)

  legend("topleft",
	 legend = c("positive", "grey zone", "imprecision zone", "negative", 
		    "analytical imprecision","confirmation threshold",
		    "initial threshold"),
	 col = c("black", "grey75", "goldenrod", "steelblue" , "red", "black", "black"),
	 lty = c(NA, NA, NA, NA, "solid", "solid", "dashed"),
	 lwd = c(NA, NA, NA, NA, 2, 2, 2),
	 pch = c(15, 15, 15, 15, NA , NA, NA))

#+end_src

#+CAPTION[]: The Low End of the GALT Activity Population Distribution. Results above the initial threshold (dashed black line) are screen negative (blue region), however samples in the "imprecision zone" (gold region) are potentially affected by analytical imprecision (red area) at the confirmation threshold (solid black line). Samples below the initial threshold (grey and black regions) are reflexed for future testing.
#+NAME: fig:imprecision
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS:
[[file:./figures/galtthresholds.pdf]]

\clearpage

#+begin_src R :session *R* :results output graphics file :file ./figures/galtthresholdsv2.pdf :exports results :tangle yes
  dens <- density(galtfilter$result)
  sd <- 0.2 ##SD at postive confirm
  confirm  <- 1.5
  initial <- confirm + (1.1*sd)
  theight  <- max(dens$y[which(dens$x <= confirm)])
  bheight  <- max(dens$y[which(dens$x <= initial)])
  ## defining the region of FN uncertainty
  start <- confirm - (6*sd)
  stop <- confirm + (6*sd)
  x2 <- seq(start,stop,0.01)
  y2 <- dnorm(x2,confirm,sd)

  ## create indices for half of the UM distribution
  halfx2 <- seq(confirm,stop,0.01)
  halfy2 <- y2[length(halfx2):length(x2)]
  fnx2 <- seq(initial,stop,0.01)
  fny2 <- y2[(length(x2) - length(fnx2)):(length(x2) -1)]

  plot(dens,type = "n", main = "",
       xlim = c(0,5),
       ylim = c(0,0.04),
       xlab = "GALT Activity U/g Hb",
       ylab = "Probability Density")
  red50 <- alpha("red", 0.5)
  ### polygons
  ## measurement error distribution
  polygon(x2,y2,type="l",col=red50, border = "red")
  polygon(dens,col = "steelblue", border = "steelblue")
  ## imprecision zome
  with(dens, polygon(x=c(stop, stop, x[x < stop]), y=c(0, y[x=stop], y[x < stop]), col="goldenrod", border = "goldenrod"))
  ## grey zone
  with(dens, polygon(x=c(initial, initial, x[x < initial]), y=c(0, y[x=initial], y[x < initial]), col="grey75", border = "grey75"))
  ## positive
  with(dens, polygon(x=c(confirm, confirm, x[x < confirm]), y=c(0, y[x=confirm], y[x < confirm]), col="black", border = "black"))
  points(x2,y2,type="l",col="red", lwd = 2) ## region of uncertainty of measurment
  ## thresholds
  abline(v = confirm, col = "black" , lty = 1, lwd = 2)
  abline(v = initial, col = "black", lty = 2, lwd = 2)

  legend("topright", inset = 0.02,
	 legend = c("positive", "grey zone", "imprecision zone", "negative", 
		    "analytical imprecision","confirmation threshold",
		    "initial threshold"),
	 col = c("black", "grey75", "goldenrod", "steelblue" , red50, "black", "black"),
	 lty = c(NA, NA, NA, NA, NA, "solid", "dashed"),
	 lwd = c(NA, NA, NA, NA, NA, 2, 2),
	 pch = c(15, 15, 15, 15, 15 , NA, NA),
	 bg = "white", 
	 box.lty = 0)
#+end_src

#+CAPTION[]: The Low End of the GALT Activity Population Distribution. Results above the initial threshold (dashed black line) are screen negative (blue region), however samples in the "imprecision zone" (gold region) are potentially affected by analytical imprecision (red area) at the confirmation threshold (solid black line). Samples below the initial threshold (grey and black regions) are reflexed for future testing.
#+NAME: fig:imprecision
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS:
[[file:./figures/galtthresholdsv2.pdf]]

\clearpage

* Supplementary Data

#+BEGIN_EXPORT LaTeX
\beginsupplement
#+END_EXPORT

#+BEGIN_SRC dot :file ./figures/algorithm.pdf :cmdline -Kdot -Tpdf
    digraph {
        node [fontsize = 18];
        first[label="Biomarker Measurement",shape="rectangle",fontcolor=white,fillcolor=steelblue3, style="rounded,filled"];
        init[label="&#8804; Initial Cutoff",shape="diamond",fillcolor= grey85, style="rounded,filled"];
        second[label="Biomarker Measurement",shape="rectangle", fontcolor=white,fillcolor=steelblue3, style="rounded,filled"];
        conf[label="&#8804; Confirmatory Cutoff",shape="diamond",fillcolor= grey85, style="rounded,filled"];
        pos[label = "Screen\nPositive", shape="rectangle", fontcolor=white,fillcolor=darkviolet, style="rounded,filled"];
        neg[label = "Screen\nNegative", shape="box", fontcolor=white,fillcolor=forestgreen, style="rounded,filled"];
        first -> init;
        init -> second[label="Yes"];
        init -> neg[label="No"];
        second-> conf;
        conf -> pos[label="Yes"];
        conf -> neg[label="No"];
  }
#+END_SRC

#+CAPTION[]: Simplified Screening Algorithm for a Disorder such as Classic Galactosemia in which Biomarker Measurements are Low. 
#+NAME: sup:algorithm
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS:
[[file:./figures/algorithm.pdf]]

